# mesa‑ads – мини‑движок видеорекламы

Этот репозиторий содержит реализацию тестового задания **Senior Go Developer**. Требовалось создать бэкенд‑сервис, который подбирает рекламный ролик перед воспроизведением видео, учитывает события (показы и клики) и корректно списывает деньги с бюджета рекламной кампании. Фронтенд не входит в задачу. Разрешены только Go и PostgreSQL; специализированные RTB‑движки и аукционные библиотеки не используются.

## Пользовательские истории

* **Зритель** получает релевантный ролик с учётом контекста (язык, география, категория контента, интересы, плейсмент) и разумного ограничения повторов; если подходящего креатива нет — отдаётся `204 No Content`.
* **Рекламодатель** видит честный расход бюджета: списание происходит один раз в соответствии с моделью оплаты (минимум CPM и CPC), соблюдаются дневные и общие лимиты.
* **Система** фиксирует события (показы и клики) и отдаёт базовую статистику: количество показов, кликов, CTR и расход.
* **Оператор** может проверить сводку по кампании за период.

## Обязательные требования (MVP)

1. **Подбор ролика.** Для каждого запроса сервис формирует список кандидатов, отфильтрованных по таргетингу (язык, гео, категория, интересы и плейсмент) и по остаткам бюджета. Для кандидатов вычисляется эффективная ставка (*eCPM*):
    * для CPM‑кампаний `eCPM = bid_cpm`;
    * для CPC‑кампаний `eCPM = bid_cpc × CTR_estimate × 1000` (оценочная вероятность клика равна 1 % по умолчанию);
    * если кампания указывает обе ставки, берётся максимальная.  Кандидаты сортируются по убыванию eCPM, и выбирается первый.
2. **Списание бюджета.** Бюджет хранится в целочисленных единицах (например, копейках). Списание защищено от гонок: в адаптере PostgreSQL используется транзакция и блокировка строки `SELECT … FOR UPDATE`.  Для CPM списание происходит при решении о показе, для CPC — при регистрации клика. Учитываются дневные и общие лимиты.
3. **Учёт событий.** Минимальные события — это **Impression** (показ) и **Click** (клик). Каждый запрос генерирует уникальный `token`, который хранится в таблицах событий. Благодаря этому обработчики идемпотентны: повторный запрос с тем же token не приведёт к двойному списанию.
4. **Мини‑статистика.** Эндпойнт `/stats/overview` возвращает агрегаты за заданный период по кампании: количество показов, кликов и сумму расходов. Параметр `campaign_id` необязателен; CTR можно вычислить на стороне клиента.

## Архитектура

Проект построен по принципам **hexagonal (ports & adapters) архитектуры**. Бизнес‑логика не зависит от конкретной базы данных или веб‑фреймворка, взаимодействие происходит через интерфейсы.

| Каталог/пакет                  | Описание |
|--------------------------------|---------|
| `cmd`                          | Точка входа приложения. Здесь происходит инициализация конфигурации, логгера, подключения к БД, запуск миграций и старт HTTP‑серверов. |
| `internal/config`              | Загрузка конфигурации из переменных окружения с помощью [caarlos0/env](https://github.com/caarlos0/env). Поддерживаются секции для логгера, HTTP‑сервера и PostgreSQL. |
| `internal/db`                  | Установка соединения с PostgreSQL через `pgxpool`. При старте приложение проверяет соединение (`Ping`) и завершает работу, если оно недоступно. |
| `internal/domain/model`        | Сущности предметной области: кампании, креативы, таргетинг, пользователи, события. Таргетинг сериализуется в JSON через методы модели. |
| `internal/domain/port`         | Интерфейсы (порты) для взаимодействия с внешним миром. Основной порт — `Repository`, описывающий операции с хранилищем. В подкаталоге `mocks` находятся сгенерированные мок‑объекты на основе `testify/mock`. |
| `internal/domain/service`      | Интерфейс `Service` описывает операции бизнес‑логики: подбор рекламы, регистрация кликов, получение статистики. Моки для сервиса можно генерировать аналогично. |
| `internal/service`             | Реализация бизнес‑логики: `AdService`. Она использует репозиторий через порт, вычисляет eCPM, создаёт события и списывает бюджеты. |
| `internal/adapter/postgres`    | Реализация репозитория на `pgxpool`. Запросы используют именованные аргументы и транзакции. Для выборки креативов применяется `pgx.CollectRows`, что сокращает количество ручного кода. |
| `internal/adapter/http`        | HTTP‑слой на основе [chi](https://github.com/go-chi/chi). Запросы разбираются в структуры, валидация упрощена. Эндпойнты: `/ad/request`, `/ad/click/{token}`, `/stats/overview`. |
| `internal/migrations`          | Функция запуска миграций через `golang‑migrate` из встроенной файловой системы (`embed.FS`). Переменная `PSQL_RUN_MIGRATIONS=true` активирует миграции при старте. |
| `db/migrations`                | SQL‑миграции (схема БД). Файлы вшиваются в бинарник. |
| `db/seeds`                     | Скрипт генерации тестовых данных. Он идемпотентен: вставки используют `ON CONFLICT DO NOTHING` и выбор существующих ID, поэтому повторный запуск не приводит к ошибкам. |
| `internal/domain/model/…`      | Логика сериализации/десериализации (например, `Targeting` имеет методы `ToJSON` и `FromJSON`). |
| `internal/util`                | Вспомогательные функции. Для работы со срезами используется стандартный пакет `slices` из Go 1.22; например, функция `slices.Contains` проверяет наличие значения в срезе【54437647339485†L627-L633】. |

### Логирование и конфигурация

В проекте используется `slog.Logger` из стандартной библиотеки. Формат (text/json) и уровень логирования (debug/info/warn/error) задаются через переменные окружения (`LOG_FORMAT`, `LOG_LEVEL`). Конфигурация считывается в структуру `Config` с помощью `env.Parse()`. Не указанные поля получают дефолтные значения.

## Миграции и сиды

SQL‑миграции находятся в каталоге `db/migrations` и автоматически применяются при старте сервиса, если установлена переменная `PSQL_RUN_MIGRATIONS=true`.  Для демонстрации статистики предусмотрен скрипт `db/seeds/seed.go`, создающий 5 кампаний, 50 креативов, около 1 000 показов и 10 000 кликов. Скрипт написан так, чтобы быть идемпотентным: он использует вставку с `ON CONFLICT DO NOTHING` и повторно считывает ID существующих записей, поэтому повторный запуск не приводит к ошибкам и не дублирует данные.

## API

Сервис предоставляет минимальный REST‑API (JSON в запросах и ответах). Примеры указаны для порта 8080.

### `POST /ad/request`

Запрос на подбор ролика. Тело запроса содержит данные пользователя и контекст видео:

```json
{
  "user_id": "123",
  "language": "ru",
  "geo": "Armenia",
  "category": "music",
  "interests": ["rock"],
  "placement": "pre-roll"
}
```

Ответ — выбранный креатив или `204 No Content`:

```json
{
  "id": 17,
  "duration": 30,
  "video_url": "https://example.com/video/17.mp4",
  "click_url": "/ad/click/4f90c8…"
}
```

### `GET /ad/click/{token}`

Регистрация клика. По полученному токену находится соответствующий показ, списывается CPC‑ставка кампании и возвращается URL посадочной страницы. При повторном обращении с тем же токеном стоимость не списывается повторно (идемпотентность), но возвращается тот же URL. Ответом является редирект (`302 Found`) на landing‑URL.

### `GET /stats/overview?from=&to=&campaign_id=`

Возвращает агрегированную статистику за период. Параметры `from` и `to` передаются в формате RFC3339; `campaign_id` необязателен. Ответ:

```json
{
  "impressions": 1000,
  "clicks": 10000,
  "cost": 500000
}
```

## Запуск

Для локального запуска потребуется Docker и docker‑compose. В корне репозитория находится `docker-compose.yml`, который поднимает PostgreSQL и приложение. Команда для старта:

```bash
docker-compose up --build
```

Сервис стартует на `http://localhost:8080`.  Миграции выполняются автоматически при наличии `PSQL_RUN_MIGRATIONS=true` в окружении. Для заполнения тестовыми данными можно выполнить сид‑скрипт внутри контейнера:

```bash
docker-compose exec mesa-ads go run db/seeds/seed.go
```

## Makefile

Репозиторий содержит `Makefile` с часто используемыми командами:

* `make generate` — запускает `go generate` для генерации моков.
* `make lint` — проверяет код линтером `golangci-lint`.
* `make fix` — пытается автоматически исправить найденные проблемы.
* `make test` — прогоняет unit‑тесты.
* `make build` — собирает бинарник `mesa-ads` из каталога `cmd`.
* `make clean` — удаляет артефакты сборки и файлы покрытия.
* `make install` — устанавливает инструменты для разработчика (`golangci-lint`, `mockery`).

## Ответы на вопросы

* **Сталкивался ли ранее с задачами AdTech?** — Да, приходилось проектировать небольшие системы для показа баннерной рекламы и работать с RTB‑аукционами. Важно учитывать высокую нагрузку и корректное списание бюджетов.
* **В чём основная сложность такого сервиса?** — Баланс между скоростью подбора объявлений и точностью таргетинга. Необходимо эффективно хранить таргетинги, избегать гонок при списании бюджета и обеспечивать идемпотентность событий.
* **В чём лично для тебя была самая большая сложность?** — Наиболее сложным был подбор оптимальной структуры данных и запросов, чтобы одновременно фильтровать по таргетингу, учитывать бюджет и ранжировать по ставке без чрезмерного усложнения SQL.
* **Как масштабировать на 10k RPS? 100k RPS? 1 млн RPS?** — Использовать connection‑pool в БД, кэшировать таргетинги в памяти, разделить сервисы (подбор/учёт) и применять шардинг по кампаниям. На уровне 1 млн RPS потребуется горизонтальное масштабирование с использованием in‑memory storage (Redis/Memcached) для быстрых выборок и асинхронная обработка событий через очередь.
* **Какие технологии использовать в проде?** — Для продовой системы потребуются устойчивый брокер (Kafka/RabbitMQ) для событий, прометей/опен‑телеметрия для метрик, централизованный логгер (Loki/Grafana), кэш (Redis), возможно gRPC для внутренних вызовов и автоматический деплой через Kubernetes.

## Допущения и упрощения

* Оценочный CTR задаётся константой 1 %. В реальной системе CTR должен вычисляться на основе накопленной статистики.
* Не реализована каппа/лимит повторов для пользователя (frequency capping). Этот функционал можно добавить на уровне репозитория, используя Redis.
* В качестве хранилища выбран PostgreSQL; в проде может потребоваться распределённая БД или NoSQL для лучшей масштабируемости.
